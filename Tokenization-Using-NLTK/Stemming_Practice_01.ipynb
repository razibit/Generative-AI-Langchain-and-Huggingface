{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:47:35.501763Z",
     "start_time": "2024-11-07T18:47:35.497411Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.stem import PorterStemmer",
   "id": "bffb768cd1933071",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:47:51.086832Z",
     "start_time": "2024-11-07T18:47:51.079975Z"
    }
   },
   "cell_type": "code",
   "source": "stemmer = PorterStemmer()",
   "id": "ec5a5b80f7124029",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:49:08.249182Z",
     "start_time": "2024-11-07T18:49:08.244467Z"
    }
   },
   "cell_type": "code",
   "source": "corpus=\"\"\"Running Runner Ran Runs Easily Heavily fairly\"\"\"",
   "id": "8059fe942f000843",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:50:03.292243Z",
     "start_time": "2024-11-07T18:50:03.287977Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.tokenize import word_tokenize",
   "id": "1df1f813340cf255",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:50:26.632313Z",
     "start_time": "2024-11-07T18:50:26.594742Z"
    }
   },
   "cell_type": "code",
   "source": "words = word_tokenize(corpus)",
   "id": "faf47ed96bfbf853",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:53:53.933978Z",
     "start_time": "2024-11-07T18:53:53.928770Z"
    }
   },
   "cell_type": "code",
   "source": "stemmed_words = [stemmer.stem(word) for word in words]",
   "id": "d9362f5af1c46a18",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:28:50.586965Z",
     "start_time": "2024-11-07T20:28:50.503685Z"
    }
   },
   "cell_type": "code",
   "source": "print(stemmed_words)",
   "id": "6651f5500514d8a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'runner', 'ran', 'run', 'easili', 'heavili', 'fairli']\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:29:26.100460Z",
     "start_time": "2024-11-07T20:29:26.036294Z"
    }
   },
   "cell_type": "code",
   "source": "stemmer.stem('congratulations')",
   "id": "cf37d0fdadaff6d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:30:23.032196Z",
     "start_time": "2024-11-07T20:30:23.022866Z"
    }
   },
   "cell_type": "code",
   "source": "stemmer.stem('maternal')",
   "id": "974853eb08d9e2c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'matern'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quantifiers\n",
    "\n",
    "Quantifiers define **how many times** a character or group should appear in a match. Here are the three main quantifiers:\n",
    "\n",
    "1. `*` (asterisk) – Matches **0 or more** occurrences of the preceding character or group.\n",
    "2. `+` (plus) – Matches **1 or more** occurrences of the preceding character or group.\n",
    "3. `{n,m}` (curly braces) – Matches **between `n` and `m`** occurrences of the preceding character or group.\n",
    "\n",
    "Let's look at each one in detail with examples.\n",
    "\n",
    "#### Example 1: `*` (Matches 0 or More Times)\n",
    "\n",
    "Suppose we want to match words ending in \"sing\" or \"ssing.\" We can use the pattern `r'ss*ing$'`:\n",
    "- The `s*` means **0 or more \"s\" characters**, so it can match either \"s\" (for \"sing\") or \"ss\" (for \"ssing\").\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "pattern = r'ss*ing$'\n",
    "words = [\"sing\", \"ssing\", \"missing\", \"assing\", \"bossing\"]\n",
    "matches = [word for word in words if re.search(pattern, word)]\n",
    "print(matches)  # Output: ['sing', 'ssing', 'missing', 'bossing']\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- The pattern `ss*ing$` finds words ending with either \"sing\" or \"ssing\" (or with \"s\" appearing multiple times before \"ing\").\n",
    "- This would also match \"missing\" and \"bossing,\" since \"s*\" can match any number of \"s\" characters, including zero.\n",
    "\n",
    "#### Example 2: `+` (Matches 1 or More Times)\n",
    "\n",
    "Let’s say we want to find words that contain at least one \"s\" followed by \"ing\". Here, we can use `s+ing$`:\n",
    "- The `s+` means **1 or more \"s\" characters**, so it will only match words that have at least one \"s\" before \"ing.\"\n",
    "\n",
    "```python\n",
    "pattern = r's+ing$'\n",
    "words = [\"sing\", \"ssing\", \"missing\", \"ing\"]\n",
    "matches = [word for word in words if re.search(pattern, word)]\n",
    "print(matches)  # Output: ['sing', 'ssing', 'missing']\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- The pattern `s+ing$` matches \"sing\", \"ssing\", and \"missing\" because each has at least one \"s\" before \"ing\".\n",
    "- It does **not** match \"ing\" because it lacks the required \"s\" character.\n",
    "\n",
    "#### Example 3: `{n,m}` (Matches Between `n` and `m` Times)\n",
    "\n",
    "Suppose we want to match words where \"s\" appears **between 1 and 2 times** before \"ing.\" We can use `s{1,2}ing$`:\n",
    "- The `{1,2}` means **between 1 and 2 occurrences** of \"s\".\n",
    "\n",
    "```python\n",
    "pattern = r's{1,2}ing$'\n",
    "words = [\"sing\", \"ssing\", \"sssings\", \"missing\", \"bossing\"]\n",
    "matches = [word for word in words if re.search(pattern, word)]\n",
    "print(matches)  # Output: ['sing', 'ssing', 'missing']\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- The pattern `s{1,2}ing$` matches \"sing\" and \"ssing\" because \"s\" appears between 1 and 2 times before \"ing\".\n",
    "- It does **not** match \"sssings\" because it has 3 \"s\" characters, which is outside the specified range.\n",
    "\n",
    "### Escaping Special Characters with `\\`\n",
    "\n",
    "Some characters have special meanings in regex. To match these characters **literally** (as plain text), we need to \"escape\" them using a backslash (`\\`). Here are some common cases:\n",
    "\n",
    "1. **`.` (dot)** – Matches any character except a newline.\n",
    "   - To match an actual dot (like in an email or URL), use `\\.`.\n",
    "\n",
    "2. **`*`, `+`, `?`, `$`** – Used for quantifiers, end of line, etc.\n",
    "   - To match them literally, prefix with `\\`.\n",
    "\n",
    "#### Example: Matching \".com\" at the End of a Word\n",
    "\n",
    "Suppose we want to match any word that ends with \".com\". We can use the pattern `r'\\.com$'`:\n",
    "- The `\\.` escapes the dot, so it matches a literal period (`.`) instead of \"any character\".\n",
    "- The `$` indicates the end of the word, so this pattern will match words that **end** with \".com\".\n",
    "\n",
    "```python\n",
    "pattern = r'\\.com$'\n",
    "words = [\"website.com\", \"mydomain.com\", \"textcom\", \"example.org\"]\n",
    "matches = [word for word in words if re.search(pattern, word)]\n",
    "print(matches)  # Output: ['website.com', 'mydomain.com']\n",
    "```\n",
    "\n",
    "Explanation:\n",
    "- The pattern `\\.com$` matches words ending with \".com\" exactly.\n",
    "- It does **not** match \"textcom\" because there is no dot before \"com\".\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Quantifiers** help define repetition: `*` (0+), `+` (1+), `{n,m}` (between `n` and `m`).\n",
    "- **Escaping special characters** with `\\` allows matching them literally, rather than using their special meanings."
   ],
   "id": "26ad12c069b500c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:16.812854Z",
     "start_time": "2024-11-08T22:11:16.806493Z"
    }
   },
   "cell_type": "code",
   "source": "from nltk.stem import RegexpStemmer",
   "id": "95f639276e840c03",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:17.166421Z",
     "start_time": "2024-11-08T22:11:17.153642Z"
    }
   },
   "cell_type": "code",
   "source": "pattern = r'(ing|ed|ly)&'",
   "id": "98dafb29c7277fe9",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:17.437189Z",
     "start_time": "2024-11-08T22:11:17.433531Z"
    }
   },
   "cell_type": "code",
   "source": "stemmer = RegexpStemmer(pattern)",
   "id": "718cff02806023c2",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:17.726177Z",
     "start_time": "2024-11-08T22:11:17.715509Z"
    }
   },
   "cell_type": "code",
   "source": "words = [\"running\", \"played\", \"quickly\", \"joyfully\", \"cat\"]",
   "id": "a0a623bdc8438eed",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:18.698424Z",
     "start_time": "2024-11-08T22:11:18.692267Z"
    }
   },
   "cell_type": "code",
   "source": "stemmed_words = [stemmer.stem(word) for word in words]",
   "id": "3b7a136b14043622",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:19.188049Z",
     "start_time": "2024-11-08T22:11:19.172387Z"
    }
   },
   "cell_type": "code",
   "source": "print(stemmed_words)",
   "id": "1c37c85309124023",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['running', 'played', 'quickly', 'joyfully', 'cat']\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:20.272550Z",
     "start_time": "2024-11-08T22:11:20.260922Z"
    }
   },
   "cell_type": "code",
   "source": "pattern1 = r'^(un|re)'",
   "id": "ca377822432256f1",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:56.714232Z",
     "start_time": "2024-11-08T22:11:56.707262Z"
    }
   },
   "cell_type": "code",
   "source": "stemmer1 = RegexpStemmer(pattern1,min=5)",
   "id": "ac2636b000c0ea67",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:57.048346Z",
     "start_time": "2024-11-08T22:11:57.044181Z"
    }
   },
   "cell_type": "code",
   "source": "words1 = [\"undo\", \"redo\", \"unanimously\", \"unknown\", \"replay\", \"relay\"]",
   "id": "baca85c1c32c3fed",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:11:57.389082Z",
     "start_time": "2024-11-08T22:11:57.376875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words1:\n",
    "    print(stemmer1.stem(word))"
   ],
   "id": "1c9c972f469b3248",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undo\n",
      "redo\n",
      "animously\n",
      "known\n",
      "play\n",
      "lay\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Combining Complex Affixes",
   "id": "56fc7e006debb061"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55875e94ec8237f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:59:47.456638Z",
     "start_time": "2024-11-09T00:59:47.449194Z"
    }
   },
   "cell_type": "code",
   "source": "pattern2 = r'^(un|re|dis|non)|ing$'",
   "id": "fa1cc5562b778700",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:59:47.827208Z",
     "start_time": "2024-11-09T00:59:47.817559Z"
    }
   },
   "cell_type": "code",
   "source": "reg_stemmer = RegexpStemmer(pattern2)",
   "id": "9a09d04597b7a04d",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:59:48.186392Z",
     "start_time": "2024-11-09T00:59:48.178459Z"
    }
   },
   "cell_type": "code",
   "source": "words2 = [\"running\",\"unload\",\"ingwalking\",\"reload\",\"disproportionate\",\"nondiscriminatory\"]",
   "id": "11ddf283d14c7c22",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T00:59:48.542260Z",
     "start_time": "2024-11-09T00:59:48.535510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for word in words2:\n",
    "    print(reg_stemmer.stem(word))"
   ],
   "id": "27884149d2ff0517",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runn\n",
      "load\n",
      "ingwalk\n",
      "load\n",
      "proportionate\n",
      "discriminatory\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Creating patterns for `RegexpStemmer` in NLTK requires an understanding of regular expressions (regex), which allow for precise control over what gets removed or modified in each word. Here’s a breakdown of instructions and rules to create effective patterns for `RegexpStemmer`.\n",
    "\n",
    "### Basic Regular Expression Rules for `RegexpStemmer`\n",
    "\n",
    "1. **Identify Affix Position:** \n",
    "   - Use `^` to indicate a **prefix** (start of a word).\n",
    "   - Use `$` to indicate a **suffix** (end of a word).\n",
    "\n",
    "   For example:\n",
    "   - `r'^un'` matches words starting with \"un\" (prefix).\n",
    "   - `r'ing$'` matches words ending with \"ing\" (suffix).\n",
    "\n",
    "2. **Match Multiple Affixes Using the OR Operator (`|`):**\n",
    "   - Use `|` to match multiple patterns in one regex.\n",
    "   - For example, `r'(ing|ed|ly)$'` matches words that end in \"ing\", \"ed\", or \"ly\".\n",
    "\n",
    "3. **Grouping Affixes with Parentheses `()`**:\n",
    "   - Parentheses group parts of the pattern, allowing you to apply the pattern to multiple affixes.\n",
    "   - For example, `r'(un|re|in)'` will match any word starting with \"un\", \"re\", or \"in\".\n",
    "\n",
    "4. **Character Classes and Sets `[]`:**\n",
    "   - Use square brackets `[]` to define a set of characters that should match one position.\n",
    "   - For example, `r'[aeiou]ing$'` matches words ending in \"ing\" that are preceded by a vowel (e.g., \"doing\", \"seeing\").\n",
    "\n",
    "5. **Quantifiers**:\n",
    "   - Quantifiers specify how many times a character or group can repeat.\n",
    "   - `*` matches 0 or more times, `+` matches 1 or more times, and `{n,m}` matches between `n` and `m` times.\n",
    "   - For example, `r'ss*ing$'` matches words ending in \"sing\" or \"ssing\".\n",
    "\n",
    "6. **Escaping Special Characters with `\\`**:\n",
    "   - Some characters like `.`, `*`, `+`, `?`, and `$` have special meanings in regex. Use `\\` to escape them when you want to match the literal character.\n",
    "   - For example, `r'\\.com$'` matches words ending with \".com\".\n",
    "\n",
    "### Steps to Design a Pattern for `RegexpStemmer`\n",
    "\n",
    "#### Step 1: Define Your Affixes\n",
    "\n",
    "Start by defining the specific affixes you want to remove. Identify whether they are prefixes or suffixes:\n",
    "- Suffixes (like `ing`, `ed`, `ly`) are removed by targeting the end of the word with `$`.\n",
    "- Prefixes (like `un`, `re`, `pre`) are removed by targeting the beginning of the word with `^`.\n",
    "\n",
    "#### Step 2: Create Patterns with `|` for Multiple Affixes\n",
    "\n",
    "If you have multiple suffixes or prefixes to remove, use the `|` operator to combine them:\n",
    "```python\n",
    "pattern = r'(ing|ed|ly)$'  # Matches any word ending in \"ing\", \"ed\", or \"ly\"\n",
    "```\n",
    "\n",
    "#### Step 3: Use Quantifiers to Target Variable-Length Affixes\n",
    "\n",
    "Quantifiers help match affixes that might vary slightly in length. For example:\n",
    "```python\n",
    "pattern = r'ing$'  # Matches any word ending with \"ing\"\n",
    "pattern = r'(ing|ings)$'  # Matches \"ing\" or \"ings\" at the end of a word\n",
    "```\n",
    "\n",
    "#### Step 4: Add Minimum Length (Optional)\n",
    "\n",
    "You may not want to stem very short words. Use `min` to set a minimum word length after stemming to prevent over-stemming:\n",
    "```python\n",
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "pattern = r'(ing|ed|ly)$'\n",
    "stemmer = RegexpStemmer(pattern, min=3)\n",
    "```\n",
    "\n",
    "#### Step 5: Test the Pattern\n",
    "\n",
    "Use sample words to test your pattern. Try various cases to ensure it works as expected.\n",
    "\n",
    "### Common Patterns for `RegexpStemmer`\n",
    "\n",
    "Here are a few common patterns and explanations:\n",
    "\n",
    "1. **Removing Common English Suffixes:**\n",
    "   ```python\n",
    "   pattern = r'(ing|ed|s|es|ly)$'\n",
    "   ```\n",
    "   - This pattern removes common suffixes like `ing`, `ed`, `s`, `es`, and `ly` at the end of a word.\n",
    "\n",
    "2. **Removing Prefixes like \"un\" and \"re\":**\n",
    "   ```python\n",
    "   pattern = r'^(un|re|in|dis|non)'\n",
    "   ```\n",
    "   - This pattern removes the prefixes `un`, `re`, `in`, `dis`, and `non` at the beginning of a word.\n",
    "\n",
    "3. **Stemming Words Ending with \"ful\", \"ness\", or \"ation\":**\n",
    "   ```python\n",
    "   pattern = r'(ful|ness|ation)$'\n",
    "   ```\n",
    "   - This pattern removes suffixes commonly used in English nouns and adjectives.\n",
    "\n",
    "4. **Removing Plurals:**\n",
    "   ```python\n",
    "   pattern = r's$'\n",
    "   ```\n",
    "   - This pattern removes a single `s` at the end of a word (for plurals), but it would also match any word ending in `s`, which can sometimes lead to over-stemming.\n",
    "\n",
    "5. **Combining Complex Affixes:**\n",
    "   ```python\n",
    "   pattern = r'^(un|re|dis|non)|ing$'\n",
    "   ```\n",
    "   - This pattern removes multiple prefixes at the start or the suffix \"ing\" at the end.\n",
    "\n",
    "### Examples of Pattern Testing\n",
    "\n",
    "Here’s an example of testing patterns with different words:\n",
    "```python\n",
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "pattern = r'(ing|ed|ly)$'\n",
    "stemmer = RegexpStemmer(pattern)\n",
    "\n",
    "words = [\"running\", \"quickly\", \"joyfully\", \"played\", \"cats\", \"runner\"]\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "print(stemmed_words)  # ['runn', 'quick', 'joyful', 'play', 'cats', 'runner']\n",
    "```\n",
    "\n",
    "### Summary\n",
    "\n",
    "To create effective patterns:\n",
    "- Use `^` for prefixes and `$` for suffixes.\n",
    "- Group multiple affixes with `|` inside `()`.\n",
    "- Control length and repetition with quantifiers.\n",
    "- Set `min` to avoid overly short stems.\n",
    "Testing the pattern on various words will help ensure it works as intended for your application."
   ],
   "id": "e8190f908e41fc73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c6fed5acfdf1367"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
